# üöá Subte Buenos Aires ‚Äî Data Warehouse & Dashboard

Proyecto de ingenier√≠a de datos y an√°lisis que construye un **Data Warehouse en modelo estrella** a partir de registros abiertos de validaciones de molinetes del Subte de Buenos Aires, integrando un pipeline completo de:

- Ingesta de datos
- Limpieza y normalizaci√≥n
- Modelado dimensional en SQL Server
- Visualizaci√≥n en Power BI

---

## üìä Objetivo

Transformar datos transaccionales crudos (CSV mensuales por l√≠nea de subte) en un sistema anal√≠tico que permita responder preguntas como:

- ¬øQu√© estaciones tienen mayor flujo de pasajeros?
- ¬øC√≥mo var√≠a la demanda por franja horaria?
- ¬øQu√© l√≠neas concentran mayor volumen?
- ¬øC√≥mo evolucionan los viajes a lo largo del tiempo?

---

## üß± Arquitectura del proyecto
CSV crudos ‚Üí ETL en Python ‚Üí Data Warehouse (SQL Server) ‚Üí Power BI

Modelo dimensional utilizado: Esquema estrella con tabla de hechos `Registros` y dimensiones de `Tiempo`, `Estaci√≥n`, `L√≠nea`, `Turno`, etc.

---

## ‚öôÔ∏è Stack tecnol√≥gico

- **Python**
- **Pandas**
- **SQLAlchemy**
- **SQL Server**
- **Power BI**

---

## üîÑ Flujo ETL

## 1Ô∏è‚É£ Concatenaci√≥n de CSV
Script: `01_concatenacion_csvs.py`

- Une archivos mensuales por l√≠nea en un √∫nico dataset.

---

## 2Ô∏è‚É£ Normalizaci√≥n de datos
Script: `02_normalizacion_datos.py`

- Unificaci√≥n de nombres de estaciones y l√≠neas.
- Correcci√≥n de inconsistencias tipogr√°ficas.
- Estandarizaci√≥n de valores categ√≥ricos.

> Durante esta etapa se realiz√≥ exploraci√≥n manual de valores √∫nicos para detectar inconsistencias (por ejemplo: estaciones con m√∫ltiples variantes de escritura), luego corregidas mediante reglas expl√≠citas en el script.

---

## 3Ô∏è‚É£ Limpieza
Script: `03_limpieza_datos.py`

- Conversi√≥n de fechas y tipos.
- Eliminaci√≥n de registros inv√°lidos.
- Preparaci√≥n del dataset final para carga en DW.

---

## 4Ô∏è‚É£ Carga en Data Warehouse
Script: `04_carga_datawarehouse.py`

- Inserci√≥n idempotente en dimensiones.
- Resoluci√≥n autom√°tica de claves for√°neas.
- Carga incremental de tabla de hechos `Registros`.

---

## üóÑÔ∏è Data Warehouse

Base de datos en **SQL Server** modelada en esquema estrella:
![Modelo](dashboard/Modelo-Estrella.png)

## Dimensiones
- `Tiempo`
- `Estacion`
- `Turno`

## Hechos
- `Registros` (cantidad de validaciones)

Script de creaci√≥n:
- `sql/01_schema_datawarehouse.sql`

Actualizaci√≥n manual de coordenadas geogr√°ficas:
- `sql/02_actualizacion_lat_long.sql`

---

## üìà Dashboard

El archivo `dashboard/powerbi_dashboard.pbix` contiene visualizaciones interactivas como:

- Flujo de pasajeros por estaci√≥n
- Evoluci√≥n temporal de validaciones
- Comparaci√≥n entre l√≠neas
- Mapas geogr√°ficos con estaciones

---

##üìå Aprendizajes clave
Construcci√≥n de pipelines ETL reproducibles

Normalizaci√≥n de datasets reales con inconsistencias sem√°nticas

Modelado dimensional (modelo estrella)

Integraci√≥n Python ‚Üí SQL Server ‚Üí Power BI

Manejo de claves for√°neas y cargas idempotentes

##üöÄ Posibles mejoras futuras
Automatizar coordenadas geogr√°ficas v√≠a API

Incorporar tests de calidad de datos

Parametrizar conexi√≥n a DB por entorno

Orquestar pipeline con Airflow o Prefect

## ‚ñ∂Ô∏è C√≥mo ejecutar el proyecto
```bash
1Ô∏è‚É£ Clonar repositorio
git clone https://github.com/tuusuario/subte-molinetes-dw.git
cd subte-molinetes-dw

2Ô∏è‚É£ Crear entorno virtual
python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt

3Ô∏è‚É£ Ejecutar pipeline
python scripts/01_concatenacion_csvs.py
python scripts/02_normalizacion_datos.py
python scripts/03_limpieza_datos.py
python scripts/04_carga_datawarehouse.py

4Ô∏è‚É£ Abrir Power BI
dashboard/powerbi_dashboard.pbix






---

##üë§ Autor
Pablo Foix
Data Analyst / Data Engineering Jr
üì´ Contacto: (pabloffoix@gmail.com)
